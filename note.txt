# this for nginx call to check if the user is authenticated
from django.http import HttpResponse
from django.contrib.auth.decorators import login_required

@login_required
def validate_session(request):
    # If decorator doesn't redirect, session is valid
    return HttpResponse(status=200)


#### NGINX ####

sudo apt update
sudo apt install nginx
sudo ufw allow 'Nginx HTTPS'
# uncomment config from /etc/nginx/nginx.conf to avoid problem of nginx seeing several server names
server_names_hash_bucket_size 64;
# create the config file with domain name and create the simlink
sudo ln -s /etc/nginx/sites-available/creditizens.local /etc/nginx/sites-enabled/
# Disable nginx until you finish writing app, enable it once all is done to enable ssl redirects and reverse proxy
sudo nginx disable


#### GUNICORN ####
pip install gunicorn
# create a config file: nano gunicorn.py
  GNU nano 6.2                                                                         gunicorn.py                                                                                   
#!/usr/bin/python3

import multiprocessing

"""Gunicorn *development* config file"""

# Django WSGI application path in pattern MODULE_NAME:VARIABLE_NAME
wsgi_app = "pdf_llm_app.wsgi:application"
# The number of worker processes for handling requests
workers = multiprocessing.cpu_count() * 2 + 1
# The granularity of Error log outputs
loglevel = "debug"
# The socket to bind
bind = "0.0.0.0:8000"
# Restart workers when code changes (development only!)
reload = True
# Write access and error info to /var/log
accesslog = errorlog = "/var/log/gunicorn/gunicorn.log"
# Redirect stdout/stderr to log file
capture_output = True
# PID file so you can easily fetch process ID
pidfile = "/var/run/gunicorn/gunicorn.pid"
# Daemonize the Gunicorn process (detach & enter background)
daemon = True


# create the directories for gunicorn files
sudo mkdir -pv /var/{log,run}/gunicorn/


#### Get 3D representation of PGVector Collections Embeddings data points ####
# Extract Data from PostgreSQL
import pandas as pd
import sqlalchemy

# Establish a connection to your PostgreSQL database
engine = sqlalchemy.create_engine('postgresql://username:password@host:port/database')

# Query to fetch data from your tables
query = """
SELECT collections.name, embeddings.x, embeddings.y, embeddings.z
FROM embeddings
JOIN collections ON embeddings.collection_id = collections.id
"""

# Load the query results into a Pandas DataFrame
df = pd.read_sql_query(query, engine)

# 3D visualization using matplotlib
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Create a 3D plot
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot using the embedding coordinates
ax.scatter(df['x'], df['y'], df['z'])

# Labeling the axes
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')

# Optional: To label each point with the name of its collection
for i, txt in enumerate(df['name']):
    ax.text(df['x'][i], df['y'][i], df['z'][i], txt, size=5)

plt.show()

#### STREAMLIT ####
# database connection
# create a file .streamlit/secrets.toml with database secrets then connect to db and query db a bit like in flask app with cursors:
import streamlit as st
conn = st.connection("pdf_embedded_db", type="sql") # Initialize connection.
df = conn.query('SELECT * FROM mytable;', ttl="10m") # Perform query ttl is to have expiry for cached db result otherwise streamlit cache it forever, disable cache with ttl=0

# can also create a .streamlit/config.toml file to ut there all configs about theme, server port, telemetry opt-in/out...etc
run : streamlit config show  # to see configs. IMPORTANT FOR PRODUCTION SO SEE VALUES AND ADD THE ONES THAT YOU FIND INTERESTING TO SET

## eg. of /.streamlit/secrets.toml:
[connections.pdf_embedded_db]  # use in your code this name to initialize db conn = st.connection("pdf_embedded_db", type="sql")
    type="sql"
    dialect="postgresql"
    username="username"
    password="password"
    host="localhsot" # IP or URL
    port=5432 # Port number
    database="db" # Database name


## eg. of /.streamlit/config.toml:
# set server port
[server]
port = 8501
# file upload size
# maxUploadSize = 200
# if want to bind server to a specific address where it listen to for client queries
# address =
# root where the streamlit app should be served from (no root directory will work so use user directories specially in Dockerfile working directory)
# baseUrlPath = ""

[browser]
# opt-out of telemetry
gatherUsageStats = false
# serverAddress = "localhost"
# serverPort = 8501 # but will defaut to server.port value

[theme]
# base =
# primaryColor =
# backgroundColor =
# secondaryBackgroundColor =
# textColor =
# font =

[logger]
# Level of logging: 'error', 'warning', 'info', or 'debug'.'
# level = "info"

## add pages to the streamlit app by creating a folder called 'pages' and putting inside .py files, each file name will be displayed as a linked text to enter the logic of the .py file representing that file. So the naming of the files are important the UI render of those, it has to be representative of what the page does UX?UI don't forget!.

# at the root directory of the streamlit app create a directory called 'static/' in order to host the app specific static files (.png, .jpg...etc...) static files not the user ones, this is the ones of your app that decorated the webui...


